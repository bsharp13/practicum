{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "mod_data = pd.read_csv('appointments_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Split into X and y\n",
    "X = mod_data.drop(\n",
    "    ['PatientId', 'AppointmentID', 'ScheduledDay', 'AppointmentDay', \n",
    "     'Neighbourhood', 'No-show', 'NoShow'], \n",
    "    axis = 1\n",
    ")\n",
    "y = mod_data.NoShow\n",
    "\n",
    "# Test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.3, random_state = 314\n",
    ")\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect x and y for each set to make resampling easier\n",
    "train = pd.DataFrame(X_train.copy())\n",
    "train['NoShow'] = y_train\n",
    "\n",
    "test = pd.DataFrame(X_test.copy())\n",
    "test['NoShow'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "train_majority = train[train['NoShow'] == 0]\n",
    "train_minority = train[train['NoShow'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sample major class\n",
    "train_majority_downsampled = resample(\n",
    "    train_majority,\n",
    "    replace = False,\n",
    "    n_samples = train_minority.shape[0],\n",
    "    random_state = 314\n",
    ")\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "train_downsampled = pd.concat([train_minority, train_majority_downsampled])\n",
    "\n",
    "# Major downsample logistic regression\n",
    "X_train = train_downsampled.drop('NoShow', axis = 1).values\n",
    "y_train = train_downsampled['NoShow']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators = 100,\n",
    "    random_state = 314\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "pred_rf = clf_rf.predict(X_test)\n",
    "\n",
    "# Gradient boosting\n",
    "clf_gb = GradientBoostingClassifier(\n",
    "    random_state = 314\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "pred_gb = clf_gb.predict(X_test)\n",
    "\n",
    "# Neural net\n",
    "clf_nn = MLPClassifier(random_state = 314).fit(X_train, y_train)\n",
    "pred_nn = clf_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.60     26377\n",
      "           1       0.19      0.48      0.28      6782\n",
      "\n",
      "   micro avg       0.49      0.49      0.49     33159\n",
      "   macro avg       0.49      0.48      0.44     33159\n",
      "weighted avg       0.66      0.49      0.54     33159\n",
      "\n",
      "Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.40      0.53     26377\n",
      "           1       0.18      0.52      0.27      6782\n",
      "\n",
      "   micro avg       0.43      0.43      0.43     33159\n",
      "   macro avg       0.47      0.46      0.40     33159\n",
      "weighted avg       0.65      0.43      0.48     33159\n",
      "\n",
      "Neural Network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.39      0.51     26377\n",
      "           1       0.16      0.47      0.24      6782\n",
      "\n",
      "   micro avg       0.40      0.40      0.40     33159\n",
      "   macro avg       0.45      0.43      0.38     33159\n",
      "weighted avg       0.62      0.40      0.45     33159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check model performance - binary outcome\n",
    "print('Random Forest')\n",
    "print(classification_report(y_test, pred_rf))\n",
    "\n",
    "print('Gradient Boosting')\n",
    "print(classification_report(y_test, pred_gb))\n",
    "\n",
    "print('Neural Network')\n",
    "print(classification_report(y_test, pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_summary(clf, data, actual):\n",
    "    \n",
    "    # Generate predicted probabilities\n",
    "    probs = clf.predict_proba(data)\n",
    "    probs = pd.Series([i[1] for i in probs])\n",
    "    \n",
    "    # Add probabilities to actuals in dataframe\n",
    "    probs_df = pd.concat([probs, actual.reset_index()], axis = 1).reset_index()\n",
    "    \n",
    "    # Clean dataframe\n",
    "    probs_df.columns = ['level_0', 'Prob', 'index', 'Actual']\n",
    "    probs_df         = probs_df.drop(['level_0', 'index'], axis = 1)\n",
    "    \n",
    "    # Round probabilities to nearest tenth\n",
    "    probs_df['RoundedProb'] = (probs_df['Prob']).round(1)\n",
    "    \n",
    "    # Summarize\n",
    "    summary = probs_df.groupby(\n",
    "        'RoundedProb'\n",
    "    ).agg(\n",
    "        {\n",
    "            'Actual':['count', 'sum']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Fix column names\n",
    "    summary.columns = [\"_\".join(i) for i in summary.columns.ravel()]\n",
    "    \n",
    "    # Calculate predicted percentages\n",
    "    summary['Actual_percentage'] = (summary['Actual_sum'] / summary['Actual_count']).round(2)\n",
    "    return(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                   622         107               0.17\n",
      "0.1                  1661         388               0.23\n",
      "0.2                  2598         661               0.25\n",
      "0.3                  3427         810               0.24\n",
      "0.4                  4899        1005               0.21\n",
      "0.5                  7247        1042               0.14\n",
      "0.6                  4615         996               0.22\n",
      "0.7                  3119         721               0.23\n",
      "0.8                  2616         603               0.23\n",
      "0.9                  1718         348               0.20\n",
      "1.0                   637         101               0.16 \n",
      "\n",
      "Gradient Boosting\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.2                    21           4               0.19\n",
      "0.3                    72          30               0.42\n",
      "0.4                   725         190               0.26\n",
      "0.5                 31563        6306               0.20\n",
      "0.6                   719         233               0.32\n",
      "0.7                    51          16               0.31\n",
      "0.8                     7           2               0.29\n",
      "0.9                     1           1               1.00 \n",
      "\n",
      "Neural Network\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.3                    21           2               0.10\n",
      "0.4                   626         108               0.17\n",
      "0.5                 31898        6548               0.21\n",
      "0.6                   614         124               0.20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check model performance - probabilities\n",
    "print('Random Forest')\n",
    "print(prob_summary(clf_rf, X_test, y_test), '\\n')\n",
    "\n",
    "print('Gradient Boosting')\n",
    "print(prob_summary(clf_gb, X_test, y_test), '\\n')\n",
    "\n",
    "print('Neural Network')\n",
    "print(prob_summary(clf_nn, X_test, y_test), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
