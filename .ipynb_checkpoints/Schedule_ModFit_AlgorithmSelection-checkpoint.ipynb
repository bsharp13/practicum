{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "mod_data = pd.read_csv('appointments_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientId', 'AppointmentID', 'Gender', 'ScheduledDay',\n",
       "       'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension',\n",
       "       'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'No-show',\n",
       "       'DaysBetween', 'NoShow', 'PreviousMiss'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = mod_data.drop(\n",
    "    [\n",
    "        'PatientId', 'AppointmentID', 'ScheduledDay', 'AppointmentDay', \n",
    "        'Neighbourhood', 'No-show', 'NoShow'\n",
    "    ], \n",
    "    axis = 1\n",
    ")\n",
    "y = mod_data.NoShow\n",
    "\n",
    "# Test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.3, random_state = 314\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "clf_lr = LogisticRegression(penalty = 'l2').fit(X_train, y_train)\n",
    "pred_lr = clf_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Regularized regression\n",
    "clf_rr = LogisticRegression(penalty = 'l1').fit(X_train, y_train)\n",
    "pred_rr = clf_rr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators = 100,\n",
    "    random_state = 314\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "pred_rf = clf_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting\n",
    "clf_gb = GradientBoostingClassifier(\n",
    "    random_state = 314\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "pred_gb = clf_gb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net\n",
    "clf_nn = MLPClassifier(random_state = 314).fit(X_train, y_train)\n",
    "pred_nn = clf_nn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularized Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     26377\n",
      "           1       0.74      0.54      0.62      6782\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     33159\n",
      "   macro avg       0.81      0.74      0.77     33159\n",
      "weighted avg       0.86      0.87      0.86     33159\n",
      "\n",
      "L1 Regularized Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     26377\n",
      "           1       0.74      0.54      0.62      6782\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     33159\n",
      "   macro avg       0.81      0.74      0.77     33159\n",
      "weighted avg       0.86      0.87      0.86     33159\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     26377\n",
      "           1       0.76      0.81      0.79      6782\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     33159\n",
      "   macro avg       0.86      0.87      0.87     33159\n",
      "weighted avg       0.91      0.91      0.91     33159\n",
      "\n",
      "Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95     26377\n",
      "           1       0.76      0.93      0.84      6782\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     33159\n",
      "   macro avg       0.87      0.93      0.89     33159\n",
      "weighted avg       0.94      0.93      0.93     33159\n",
      "\n",
      "Neural Network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95     26377\n",
      "           1       0.76      0.93      0.84      6782\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     33159\n",
      "   macro avg       0.87      0.93      0.89     33159\n",
      "weighted avg       0.94      0.93      0.93     33159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check model performance - binary outcome\n",
    "print('L2 Regularized Logistic Regression')\n",
    "print(classification_report(y_test, pred_lr))\n",
    "\n",
    "print('L1 Regularized Logistic Regression')\n",
    "print(classification_report(y_test, pred_rr))\n",
    "\n",
    "print('Random Forest')\n",
    "print(classification_report(y_test, pred_rf))\n",
    "\n",
    "print('Gradient Boosting')\n",
    "print(classification_report(y_test, pred_gb))\n",
    "\n",
    "print('Neural Network')\n",
    "print(classification_report(y_test, pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_summary(clf, data, actual):\n",
    "    \n",
    "    # Generate predicted probabilities\n",
    "    probs = clf.predict_proba(data)\n",
    "    probs = pd.Series([i[1] for i in probs])\n",
    "    \n",
    "    # Add probabilities to actuals in dataframe\n",
    "    probs_df = pd.concat([probs, actual.reset_index()], axis = 1).reset_index()\n",
    "    \n",
    "    # Clean dataframe\n",
    "    probs_df.columns = ['level_0', 'Prob', 'index', 'Actual']\n",
    "    probs_df         = probs_df.drop(['level_0', 'index'], axis = 1)\n",
    "    \n",
    "    # Round probabilities to nearest tenth\n",
    "    probs_df['RoundedProb'] = (probs_df['Prob']).round(1)\n",
    "    \n",
    "    # Summarize\n",
    "    summary = probs_df.groupby(\n",
    "        'RoundedProb'\n",
    "    ).agg(\n",
    "        {\n",
    "            'Actual':['count', 'sum']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Fix column names\n",
    "    summary.columns = [\"_\".join(i) for i in summary.columns.ravel()]\n",
    "    \n",
    "    # Calculate predicted percentages\n",
    "    summary['Actual_percentage'] = (summary['Actual_sum'] / summary['Actual_count']).round(2)\n",
    "    return(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularized Logistic Regression\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                 16869           0               0.00\n",
      "0.1                  5835           0               0.00\n",
      "0.2                   352          15               0.04\n",
      "0.3                  1890         908               0.48\n",
      "0.4                  2370        1499               0.63\n",
      "0.5                  1828        1414               0.77\n",
      "0.6                  1157         955               0.83\n",
      "0.7                   458         400               0.87\n",
      "0.8                   180         151               0.84\n",
      "0.9                  1211         728               0.60\n",
      "1.0                  1009         712               0.71 \n",
      "\n",
      "L1 Regularized Logistic Regression\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                 16862           0               0.00\n",
      "0.1                  5840           0               0.00\n",
      "0.2                   356          15               0.04\n",
      "0.3                  1890         905               0.48\n",
      "0.4                  2370        1503               0.63\n",
      "0.5                  1826        1413               0.77\n",
      "0.6                  1157         955               0.83\n",
      "0.7                   458         400               0.87\n",
      "0.8                   182         151               0.83\n",
      "0.9                  1209         728               0.60\n",
      "1.0                  1009         712               0.71 \n",
      "\n",
      "Random Forest\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                 23429          70               0.00\n",
      "0.1                   325          95               0.29\n",
      "0.2                   553         248               0.45\n",
      "0.3                   686         313               0.46\n",
      "0.4                   603         327               0.54\n",
      "0.5                   744         488               0.66\n",
      "0.6                   760         499               0.66\n",
      "0.7                   973         697               0.72\n",
      "0.8                  1297         981               0.76\n",
      "0.9                  1643        1277               0.78\n",
      "1.0                  2146        1787               0.83 \n",
      "\n",
      "Gradient Boosting\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                 23091           0               0.00\n",
      "0.1                     1           0               0.00\n",
      "0.2                   988         211               0.21\n",
      "0.3                   391         108               0.28\n",
      "0.4                   352         144               0.41\n",
      "0.5                    66          38               0.58\n",
      "0.6                  1378         869               0.63\n",
      "0.7                  2519        1803               0.72\n",
      "0.8                  3010        2420               0.80\n",
      "0.9                  1360        1186               0.87\n",
      "1.0                     3           3               1.00 \n",
      "\n",
      "Neural Network\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                 23091           0               0.00\n",
      "0.1                    13           1               0.08\n",
      "0.2                   443          86               0.19\n",
      "0.3                   983         252               0.26\n",
      "0.4                   259         105               0.41\n",
      "0.5                    88          48               0.55\n",
      "0.6                   447         273               0.61\n",
      "0.7                  2743        1888               0.69\n",
      "0.8                  3568        2788               0.78\n",
      "0.9                  1489        1308               0.88\n",
      "1.0                    35          33               0.94 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check model performance - probabilities\n",
    "print('L2 Regularized Logistic Regression')\n",
    "print(prob_summary(clf_lr, X_test, y_test), '\\n')\n",
    "\n",
    "print('L1 Regularized Logistic Regression')\n",
    "print(prob_summary(clf_rr, X_test, y_test), '\\n')\n",
    "\n",
    "print('Random Forest')\n",
    "print(prob_summary(clf_rf, X_test, y_test), '\\n')\n",
    "\n",
    "print('Gradient Boosting')\n",
    "print(prob_summary(clf_gb, X_test, y_test), '\\n')\n",
    "\n",
    "print('Neural Network')\n",
    "print(prob_summary(clf_nn, X_test, y_test), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variable importance of best models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Schedule_gb00.pkl\", 'wb') as file:  \n",
    "    pickle.dump(clf_gb, file)\n",
    "    \n",
    "with open(\"Schedule_mlp00.pkl\", 'wb') as file:  \n",
    "    pickle.dump(clf_nn, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
