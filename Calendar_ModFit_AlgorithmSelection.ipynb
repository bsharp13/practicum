{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "mod_data = pd.read_csv('appointments_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientId', 'AppointmentID', 'Gender', 'ScheduledDay',\n",
       "       'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension',\n",
       "       'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'No-show',\n",
       "       'DaysBetween', 'NoShow', 'PreviousMiss'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = mod_data[['DaysBetween', 'Age', 'Gender']]\n",
    "y = mod_data.NoShow\n",
    "\n",
    "# Test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.3, random_state = 314\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "clf_lr = LogisticRegression(penalty = 'l2').fit(X_train, y_train)\n",
    "pred_lr = clf_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Regularized regression\n",
    "clf_rr = LogisticRegression(penalty = 'l1').fit(X_train, y_train)\n",
    "pred_rr = clf_rr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators = 100,\n",
    "    random_state = 314\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "pred_rf = clf_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting\n",
    "clf_gb = GradientBoostingClassifier(\n",
    "    random_state = 314\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "pred_gb = clf_gb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net\n",
    "clf_nn = MLPClassifier(random_state = 314).fit(X_train, y_train)\n",
    "pred_nn = clf_nn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularized Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88     26377\n",
      "           1       0.37      0.02      0.03      6782\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     33159\n",
      "   macro avg       0.59      0.51      0.46     33159\n",
      "weighted avg       0.71      0.79      0.71     33159\n",
      "\n",
      "L1 Regularized Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88     26377\n",
      "           1       0.37      0.02      0.03      6782\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     33159\n",
      "   macro avg       0.59      0.51      0.46     33159\n",
      "weighted avg       0.71      0.79      0.71     33159\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87     26377\n",
      "           1       0.37      0.13      0.20      6782\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     33159\n",
      "   macro avg       0.59      0.54      0.53     33159\n",
      "weighted avg       0.72      0.78      0.73     33159\n",
      "\n",
      "Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89     26377\n",
      "           1       0.29      0.00      0.00      6782\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     33159\n",
      "   macro avg       0.54      0.50      0.44     33159\n",
      "weighted avg       0.69      0.80      0.71     33159\n",
      "\n",
      "Neural Network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89     26377\n",
      "           1       0.00      0.00      0.00      6782\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     33159\n",
      "   macro avg       0.40      0.50      0.44     33159\n",
      "weighted avg       0.63      0.80      0.70     33159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Check model performance - binary outcome\n",
    "print('L2 Regularized Logistic Regression')\n",
    "print(classification_report(y_test, pred_lr))\n",
    "\n",
    "print('L1 Regularized Logistic Regression')\n",
    "print(classification_report(y_test, pred_rr))\n",
    "\n",
    "print('Random Forest')\n",
    "print(classification_report(y_test, pred_rf))\n",
    "\n",
    "print('Gradient Boosting')\n",
    "print(classification_report(y_test, pred_gb))\n",
    "\n",
    "print('Neural Network')\n",
    "print(classification_report(y_test, pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_summary(clf, data, actual):\n",
    "    \n",
    "    # Generate predicted probabilities\n",
    "    probs = clf.predict_proba(data)\n",
    "    probs = pd.Series([i[1] for i in probs])\n",
    "    \n",
    "    # Add probabilities to actuals in dataframe\n",
    "    probs_df = pd.concat([probs, actual.reset_index()], axis = 1).reset_index()\n",
    "    \n",
    "    # Clean dataframe\n",
    "    probs_df.columns = ['level_0', 'Prob', 'index', 'Actual']\n",
    "    probs_df         = probs_df.drop(['level_0', 'index'], axis = 1)\n",
    "    \n",
    "    # Round probabilities to nearest tenth\n",
    "    probs_df['RoundedProb'] = (probs_df['Prob']).round(1)\n",
    "    \n",
    "    # Summarize\n",
    "    summary = probs_df.groupby(\n",
    "        'RoundedProb'\n",
    "    ).agg(\n",
    "        {\n",
    "            'Actual':['count', 'sum']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Fix column names\n",
    "    summary.columns = [\"_\".join(i) for i in summary.columns.ravel()]\n",
    "    \n",
    "    # Calculate predicted percentages\n",
    "    summary['Actual_percentage'] = (summary['Actual_sum'] / summary['Actual_count']).round(2)\n",
    "    return(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularized Logistic Regression\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.1                  7647         753               0.10\n",
      "0.2                 19898        4051               0.20\n",
      "0.3                  3973        1391               0.35\n",
      "0.4                  1069         383               0.36\n",
      "0.5                   403         151               0.37\n",
      "0.6                   122          39               0.32\n",
      "0.7                    24           7               0.29\n",
      "0.8                    10           4               0.40\n",
      "0.9                    13           3               0.23 \n",
      "\n",
      "L1 Regularized Logistic Regression\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.1                  7647         753               0.10\n",
      "0.2                 19899        4051               0.20\n",
      "0.3                  3972        1391               0.35\n",
      "0.4                  1069         383               0.36\n",
      "0.5                   403         151               0.37\n",
      "0.6                   122          39               0.32\n",
      "0.7                    24           7               0.29\n",
      "0.8                    10           4               0.40\n",
      "0.9                    13           3               0.23 \n",
      "\n",
      "Random Forest\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                 10429         841               0.08\n",
      "0.1                  5828         913               0.16\n",
      "0.2                  5764        1455               0.25\n",
      "0.3                  4628        1316               0.28\n",
      "0.4                  2990         981               0.33\n",
      "0.5                  1788         612               0.34\n",
      "0.6                   694         259               0.37\n",
      "0.7                   547         216               0.39\n",
      "0.8                   244          93               0.38\n",
      "0.9                   157          57               0.36\n",
      "1.0                    90          39               0.43 \n",
      "\n",
      "Gradient Boosting\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                  9151         308               0.03\n",
      "0.1                  2535         231               0.09\n",
      "0.2                  7827        1716               0.22\n",
      "0.3                  9348        2822               0.30\n",
      "0.4                  4256        1689               0.40\n",
      "0.5                    36          16               0.44\n",
      "0.6                     6           0               0.00 \n",
      "\n",
      "Neural Network\n",
      "             Actual_count  Actual_sum  Actual_percentage\n",
      "RoundedProb                                             \n",
      "0.0                  9193         318               0.03\n",
      "0.1                  2639         296               0.11\n",
      "0.2                  9820        2218               0.23\n",
      "0.3                  9660        3210               0.33\n",
      "0.4                  1846         739               0.40\n",
      "0.5                     1           1               1.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check model performance - probabilities\n",
    "print('L2 Regularized Logistic Regression')\n",
    "print(prob_summary(clf_lr, X_test, y_test), '\\n')\n",
    "\n",
    "print('L1 Regularized Logistic Regression')\n",
    "print(prob_summary(clf_rr, X_test, y_test), '\\n')\n",
    "\n",
    "print('Random Forest')\n",
    "print(prob_summary(clf_rf, X_test, y_test), '\\n')\n",
    "\n",
    "print('Gradient Boosting')\n",
    "print(prob_summary(clf_gb, X_test, y_test), '\\n')\n",
    "\n",
    "print('Neural Network')\n",
    "print(prob_summary(clf_nn, X_test, y_test), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Calendar_gb00.pkl\", 'wb') as file:  \n",
    "    pickle.dump(clf_gb, file)\n",
    "    \n",
    "with open(\"Calendar_mlp00.pkl\", 'wb') as file:  \n",
    "    pickle.dump(clf_nn, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
